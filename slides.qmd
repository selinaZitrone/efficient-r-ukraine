---
title: "Efficient R"
subtitle: "Workshop for :ukraine:"
author: "Selina Baldauf"
format: 
  revealjs:
    footer: "Selina Baldauf // Efficient R"
    mainfont: Cabinet Grotesk
    slide-number: true
    show-slide-number: all
    incremental: true
    self-contained: true
    code-line-numbers: false
    theme: slides.scss
    auto-stretch: false
    scrollable: true
execute: 
  echo: true
  eval: true
  cache: true
  message: false
knitr: 
  opts_chunk: 
    collapse: true
    comment: "#>" 
from: markdown+emoji
editor: source
---

```{r}
#| label: setup
#| include: false
#| cache: false
ggplot2::theme_set(ggplot2::theme_gray(base_size = 16))

library(tictoc)
```

## Welcome

- Selina Baldauf
- Scientific programmer at the Freie Universität Berlin
  - Theoretical ecology 
  - My background: PhD in ecology, more and more interested in programming
  - Besides doing some research myself 
- Reach out via email or bluesky

## What is efficiency?

$$
\textsf{efficiency} = \frac{\textsf{work done}}{\textsf{unit of effort}}
$$
<br>

:::{.columns}

:::{.column width="50%"}

:::{.fragment}

**Computational efficiency**

:::

:::{.fragment}

:computer: Computation time <br>
:floppy_disk: Memory usage

:::

:::

:::{.column width="50%"}

::: {.fragment}

**Programmer efficiency** 

🧍 How long does it take to

:::

- *write* code?
- *maintain* code?
- *read* and *understand* the code?

:::


:::

. . .

**Tradeoffs** and **Synergies** between these types of efficiencies

---

:::{.r-stack}

![](img/pyramid_1.png){fig-align="center" .fragment}

![](img/pyramid_2.png){fig-align="center" .fragment}

![](img/pyramid_text.png){fig-align="center" .fragment}


:::

. . .

**Principles** and **tools** to make R programming more efficient for the :computer:

## Today

Focus on speed, not memory.

- How to **measure speed** of your code
- **Basics** of efficient R programming
- Efficient **data analysis**
- Advanced optimization
  - **Parallelization**
  - Integrating **C++**

## Is R slow?

- R is slow compared to other programming languages (e.g. C++, Julia).

- R is the not the most memory efficient language

- R is designed to make statistical programming & data analysis **easy** and **interactive**, not fast
  
- But: [R is fast and memory efficient enough]{.highlight-purple} for most tasks.

## Should I optimize?

. . .

> It’s easy to get caught up in trying to remove all bottlenecks. Don’t! **Your time is valuable** and is **better spent analysing your data**, not eliminating possible inefficiencies in your code. **Be pragmatic**: don’t spend hours of your time to save seconds of computer time.<br>
(Hadley Wickham in [Advanced R](https://adv-r.hadley.nz/perf-improve.html))

. . .
<br>
#### Think about

- How much time do I **save** vs. **spend** optimizing? 
- **How often** do I run the code?
- Trade-offs between **readability** and **efficiency**

## Should I optimize? {visibility="hidden"}

If your code is too slow for you, you can go through these steps:

1. Can you just **run the code somewhere else**?

## Run the code somewhere else

Useful if the you are blocked from doing other things at the same time:

:::{.fragment}

:::{.nonincremental}

- Use RStudio **background jobs**

![](img/background_job.png){width=40%}

:::

:::

:::{.fragment}

:::{.nonincremental}

- Start your R script from the command line

:::

```bash
Rscript my_script.R
```
:::

:::{.fragment}

:::{.nonincremental}

- Run it on a cluster

:::

:::

## Should I optimize?

If your code is to slow for you, you can go through these steps:

:::{.nonincremental}

1. Can you just **run the code somewhere else**?

:::

1. **Identify bottlenecks** (i.e. slow parts) of your code
2. **Optimize** only those bottlenecks

# Profiling and benchmarking

> Measure the speed and memory usage of your code

## Profiling R code

What are the speed & memory **bottlenecks** in my code?

. . .

Use the [`profvis` package](https://rstudio.github.io/profvis/)

## Profiling R code

You can profile a section of code like this:

```{r eval=FALSE}
#| label: profvis
#| eval: false
#| code-line-numbers: "1-2|5-16|4,17"
# install.packages("profvis")
library(profvis)

profvis({
  # Create a data frame with 150 columns and 200000 rows
  df <- as.data.frame(matrix(rnorm(150 * 200000), nrow = 200000))

  # Calculate mean of each column
  means <- apply(df, 2, mean)

  # Subtract means
  for (i in seq_along(means)) {
    df[, i] <- df[, i] - means[i]
    # Simulate inefficiency by sleeping for 0.01 seconds
    Sys.sleep(0.01)
  }
})
```

## Profiling R code

Profvis **flame graph** shows time and memory spent in each line of code.

![](img/profvis-flame.png){width=80% fig-align="center"}

## Profiling R code

Profvis **data view** for details of the call stack.

![](img/profvis-data.png)

## Profiling R code

You can also interactively profile code in RStudio:

::: {.nonincremental}

- Go to **Profile -> Start profiling**
- Now interactively run the code you want to profile
- Go to **Profile -> Stop profiling** to see the results

:::

![](img/profiling_rstudio.png)

## Benchmarking R code

Which version of the code is faster?

. . .


::: {.columns}

::: {.column}

```{r}
#| label: define-center_data_slow
center_data_slow <- function() {
  # Create data with 150 columns and 100000 rows
  df <- as.data.frame(matrix(rnorm(150 * 100000), nrow = 100000))

  # Calculate mean of each column
  means <- apply(df, 2, mean)

  # Subtract means
  for (i in seq_along(means)) {
    df[, i] <- df[, i] - means[i]
    # Simulate inefficiency by sleeping for 0.01 seconds
    Sys.sleep(0.01)
  }
  return(df)
}
```

:::


::: {.column}

```{r}
#| label: define-center_data_fast
center_data_fast <- function() {
  # Create data with 150 columns and 100000 rows
  df <- matrix(rnorm(150 * 100000), nrow = 100000)

  # Calculate mean of each column
  means <- colMeans(df)

  # Subtract means
  for (i in seq_along(means)) {
    df[, i] <- df[, i] - means[i]
  }
  return(df)
}
```

:::

:::

## Benchmarking R code - the easy way

Use the `system.time()` function for simple function calls:

```{r}
system.time(center_data_slow())
system.time(center_data_fast())
```

. . .

Use the `tictoc` package also for longer code sections:

```{r}
#| label: tic-toc
# install.packages("tictoc")
library(tictoc)

tic()
slow_data <- center_data_slow()
toc()

tic()
fast_data <- center_data_fast()
toc()
```

## Benchmarking R code

Use the `microbenchmark` package to compare the functions:

. . .

```{r}
#| label: benchmark-center-data
#| code-line-numbers: 1-8|9-15|9-21
# install.packages("microbenchmark")
library(microbenchmark)

runtime_comp <- microbenchmark(
  slow = center_data_slow(),
  fast = center_data_fast(),
  times = 10 # the default is 100 but we are impatient
)

runtime_comp

# look at relative runtime comparison
summary(runtime_comp, unit = "relative")
```

## Benchmarking R code

We can look at benchmarking results using ggplot

```{r}
#| label: autoplot-compare-functions
#| output-location: fragment
#| out-width: "80%"
library(ggplot2)
autoplot(runtime_comp)
```

# Optimize your code

:::{.nonincremental}

- Basic principles
- Data analysis bottlenecks
- Advanced optimization: Parallelization and C++
  
:::

# Basic principles

## Vectorize your code

- Vectors are central to R programming
- R is optimized for vectorized code
  - Implemented directly in C/Fortran
- Vector operations can often replace for-loops in R
- If there is a vectorized version of a function: Use it

## Vectorized functions in R

Some examples of base-R vectorized functions:

:::{.nonincremental}

- Arithmetic & Math: `+`, `-`, `*`, `/`, `log()`, `exp()`, `sqrt()`, `mean()`, `sd()`, `rowSums()`, `colMeans()`
- Logical & Comparison: `<`, `>`, `==`, `!=`, `&`, `|`, `all()`, `any()`, `%in%`
- Data Manipulation: `[`, `ifelse()`, `cut()`, `cumsum()`, `which()`, `match()`, `order()`
- String operations: `paste()`, `paste0()`, `grep()`, `gsub()` 
:::

## Vectorize your code

::: {.panel-tabset}

## Vector arithmetic vs. for-loops

```{r}
#| label: benchmark-vectorization
#| output-location: fragment
x <- 1:1e6
y <- 1:1e6

microbenchmark(
  for_loop = {
    result <- numeric(length(x))
    for (i in seq_along(x)) {
      result[i] <- x[i] * 2 + y[i] / 2
    }
  },
  vectorized = x * 2 + y / 2,
  times = 10
)
```

## Example 2: Calculating cumulative values

```{r}
#| label: benchmark-cumsum
#| output-location: fragment
x <- sample(1:100, 1e5, replace = TRUE)

microbenchmark(
  for_loop = {
    result <- numeric(length(x))
    sum_so_far <- 0
    for (i in seq_along(x)) {
      sum_so_far <- sum_so_far + x[i]
      result[i] <- sum_so_far
    }
  },
  vectorized = cumsum(x),
  times = 10
)
```

:::

## For-loops in R

- For-loops are **relatively slow** and it is easy to make them even slower with bad design
- Often they are used when vectorized code would be better

- For loops can often be replaced, e.g. by
  - Functions from the apply family (e.g. `apply`, `lapply`, ...)
  - Vectorized functions (e.g. `sum`, `colMeans`, ...)
  - Vectorized functions from the [`purrr` package](https://purrr.tidyverse.org/) (e.g. `map`)
  
. . .

But: For loops are not necessarily bad, **sometimes** they are the **best solution** and **more readable** than vectorized code.

## Don't grow objects in a loop

If you know how big your object will be, pre-allocate it.

::: {.columns}
::: {.column}

```{r}
#| label: create-f1-loop
f1 <- function() {
  x <- numeric() # no pre-allocation
  for (i in 1:1e6) {
    x[i] <- i
  }
}
```

:::
::: {.column}

```{r}
#| label: create-f2-loop
f2 <- function() {
  x <- numeric(1e4) # pre-allocate vector
  for (i in 1:1e6) {
    x[i] <- i
  }
}

```

:::
::: 

. . .

<br>

```{r}
#| label: benchmark-f1-f2-loop
#| output-location: fragment

compare_alloc <- microbenchmark(
  no_alloc = f1(),
  pre_alloc = f2(),
  times = 10
)

summary(compare_alloc, unit = "relative")
```

## Don't grow objects in a loop

### Why?

R makes a copy of the object each time it grows, which is inefficient.

## Don't grow objects in a loop

```{r}
#| label: trace-memory
x <- numeric()
y <- numeric(10)

for (i in 1:10) {
  x[i] <- i
  y[i] <- i

  # Force a print of the current memory location after each assignment
  cat(
    "After iteration ",
    i,
    ": x is in ",
    address(x),
    "and y is in ",
    address(y),
    "\n"
  )
}
```

## Cache variables

If you use a value multiple times, store it in a variable to avoid re-calculation

. . .

**Example**: Calculate column means and normalize them by the standard deviation

. . .

```{r}
#| label: cache-variables
#| code-line-numbers: 1-3|4-10|11-14
# A matrix with 1000 columns
x <- matrix(rnorm(10000), ncol = 1000)

microbenchmark(
  no_cache = apply(x, 2, function(i) mean(i) / sd(x)),
  cache = {
    sd_x <- sd(x)
    apply(x, 2, function(i) mean(i) / sd_x)
  }
)
```

# Efficient data analysis

## Efficient workflow

- Filter early: Remove unnecessary rows/columns at the beginning
- Avoid redundant calculations
  - Calculate values once and store them in variables
  - Save intermediate results
- Use efficient data formats
  - Text files instead of Excel files
  - Binary formats like Parquet and feather for large datasets
  - Consider SQL for very large datasets
- Use the right packages and functions for your tasks

## The packages

- `tidyverse`
- `data.table`
- `collapse`
- `arrow`


## Read data

**Example:** Read csv data on global greenhouse gas emissions (~320000 rows, 8 cols).

```{r}
#| label: warmup-reading
#| echo: false
file_path_csv <- here::here("data/ghg_ems_large.csv")
file_path_xlsx <- here::here("data/ghg_ems_large.xlsx")

dummy <- readr::read_csv(file_path_csv)
dummy <- read.csv(file_path_csv)
dummy <- data.table::fread(file_path_csv)
dummy <- arrow::read_csv_arrow(file_path_csv)
rm(dummy)
```

  
```{r}
#| label: benchmark-reading-data
#| message: false
#| output-location: slide
file_path_csv <- here::here("data/ghg_ems_large.csv")
file_path_xlsx <- here::here("data/ghg_ems_large.xlsx")

compare_read <- microbenchmark(
  read.csv = read.csv(file_path_csv),
  read_csv = readr::read_csv(
    file_path_csv,
    show_col_types = FALSE
  ),
  fread = data.table::fread(file_path_csv, showProgress = FALSE),
  read_csv_arrow = arrow::read_csv_arrow(file_path_csv),
  read_excel = readxl::read_excel(file_path_xlsx),
  times = 10
)

autoplot(compare_read)
```

## Read data

Binary file types can be faster (especially as file size increases)

```{r}
#| label: benchmark-reading-binary
#| output-location: slide
file_path_parquet <- here::here("data/ghg_ems_large.parquet")
file_path_fst <- here::here("data/ghg_ems_large.fst")

compare_read_binary <- microbenchmark(
  read_csv = readr::read_csv(file_path_csv, show_col_types = FALSE),
  read_fread = data.table::fread(
    file_path_csv,
    showProgress = FALSE
  ),
  read_parquet = arrow::read_parquet(file_path_parquet),
  read_fst = fst::read_fst(file_path_fst),
  times = 10
)

autoplot(compare_read_binary)
```

## Write data

Every corresponding read function has a write counterpart:

- `write_csv` from the `readr` package (tidyverse)
- `fwrite` from the `data.table` package
- `write_csv_arrow`, `write_parquet` from the `arrow` package
- `write_fst` from the `fst` package

## Write data

```{r}
#| label: benchmark-writing-data
#| output-location: slide

# create an example with 10000 rows to export
df <- data.frame(
  x = 1:100000,
  y = 1:100000,
  z = 1:100000
)

compare_output <- microbenchmark::microbenchmark(
  write.csv = write.csv(df, "df.csv"),
  write_csv = readr::write_csv(df, "df.csv"),
  fwrite = data.table::fwrite(df, "df.csv"),
  write_excel = writexl::write_xlsx(df, "df.xlsx"),
  write_csv_arrow = arrow::write_csv_arrow(df, "df.csv"),

  # Write binary formats
  write_parquet = arrow::write_parquet(sample_data, "data/df.parquet"),
  write_fst = fst::write_fst(sample_data, "data/df.fst"),
  times = 10
)

autoplot(compare_output)
```

## Efficient data manipulation

Different packages offer fast and efficient data manipulation and analysis:

- `dplyr` package has a C++ backend and is often faster than base R
- `data.table` package is fast and memory efficiency
  - Syntax is quite different from base R and `tidyverse`
- `collapse` package is a C++ based and specifically developed for fast data analysis
  - Works together with both `tidyverse` and `data.table` workflows
  - Many functions similar to base R or `dplyr` just with prefix "f" (e.g. `fselect`, `fmean`, ...)
- `arrow` package for efficient reading, processing and writing of large datasets (even larger than RAM)

## Summarize data by group

**Example**: Summarize mean carbon emissions from Electricity by Country

```{r}
#| label: setup-summarize-by-group
library(data.table)
library(dplyr)
library(collapse)
```

## Summarize data by group

**Example**: Summarize mean carbon emissions from Electricity by Country

```{r}
#| label: load-ghg-ems
#| include: false
ghg_ems <- data.table::fread(here::here("data/ghg_ems.csv"))
```

```{r}
#| label: functions-summarize-by-group
#| code-line-numbers: 1-7|8-13|14-20
# 1. The data table way
# Convert the data to a data.table
setDT(ghg_ems)
summarize_dt <- function() {
  ghg_ems[, mean(Electricity, na.rm = TRUE), by = Country]
}

# 2. The dplyr way
summarize_dplyr <- function() {
  ghg_ems |>
    group_by(Country) |>
    summarize(mean_e = mean(Electricity, na.rm = TRUE))
}

# 3. The collapse way
summarize_collapse <- function() {
  ghg_ems |>
    fgroup_by(Country) |>
    fsummarise(mean_e = fmean(Electricity))
}
```

## Efficient data manipulation

**Example**: Summarize mean carbon emissions from Electricity by Country

```{r}
#| label: benchmark-summarizing-by-group
# compare the speed of all versions
microbenchmark(
  dplyr = summarize_dplyr(),
  data_table = summarize_dt(),
  collapse = summarize_collapse(),
  times = 10
)
```

## Select columns

**Example**: Select columns Country, Year, Electricity, Transportation

```{r}
#| label: benchmark-selecting-columns
#| code-line-numbers: 1-6|7-11
#| output-location: fragment
microbenchmark(
  dplyr = select(ghg_ems, Country, Year, Electricity, Transportation),
  data_table = ghg_ems[, .(Country, Electricity, Transportation)],
  collapse = fselect(ghg_ems, Country, Electricity, Transportation),
  times = 10
)
```

# Advanced optimization

> Parallelization and C++

## Parallelization

By default, R works on one core but CPUs have multiple cores

. . .

```{r}
#| label: find-available-cores
# Find out how many cores you have with the parallel package
# install.packages("parallel")
parallel::detectCores()
```

. . .

<br>

::::{.columns}

::: {.column width="50%"}

Sequential

![](img/sequential.png){width="40%" fig-align="center"}

:::

::: {.column width="50%"}

:::{.fragment}

Parallel

![](img/parallel.png)

:::

:::

::::

## Parallelization with the futureverse

- `future` is a framework to help you parallelize existing R code
  - Parallel versions of base R apply family
  - Parallel versions of `purrr` functions
  - Parallel versions of `foreach` loops
- Find more details [here](https://www.futureverse.org/)
- Find a tutorial for different use cases [here](https://henrikbengtsson.github.io/future-tutorial-user2022)

## A slow example

Let's create a very slow square root function

```{r}
#| label: slow-sqrt
slow_sqrt <- function(x) {
  Sys.sleep(1) # simulate 1 second of computation time
  sqrt(x)
}
```

. . .

Before you run anything in parallel, tell R how many cores to use:

```{r}
#| label: plan-parallel
# Load future package
library(future)
# Plan parallel session with 6 cores
plan(multisession, workers = 6)
```	

## Parallel apply functions

To run the function on a vector of numbers we could use

:::{.columns}

:::{.column width="50%"}

**Sequential** **`lapply`** <br>

```{r}
#| label: lapply-slow-sqrt
#| message: false
# create a vector of 10 numbers
x <- 1:10
tic()
result <- lapply(x, slow_sqrt)
toc()
```

:::

:::{.column width="50%"}

:::{.fragment}

**Parallel** **`future_lapply`** <br>

```{r}
#| label: future-lapply-slow-sqrt
#| eval: false
# Load future.apply package
library(future.apply)

tic()
result <- future_lapply(x, slow_sqrt)
toc()
#> 2.6 sec elapsed
```

:::

:::

:::

. . .

Use `parallel::detectCores()` to find out how many cores you have.

## Parallel apply functions

Selected base R apply functions and their future versions:

```{r}
#| label: apply-functions-table
#| echo: false
# A data. frame with two columns: base and future.apply
# In the base column there are the base R functions and in the future.apply
# column there are the future versions of the functions
# The function names should be enclosed in backticks and then in quotation marks to be printed nicely
apply_functions <- data.frame(
  base = c(
    "`
lapply
`",
    "`
sapply
`",
    "`
vapply
`",
    "`
mapply
`",
    "`
tapply
`",
    "`
apply
`",
    "`
Map
`"
  ),
  future.apply = c(
    "`
future_lapply
`",
    "`
future_sapply
`",
    "`
future_vapply
`",
    "`
future_mapply
`",
    "`
future_tapply
`",
    "`
future_apply
`",
    "`
future_Map
`"
  )
)
# print the data frame apply_functions nicely in the quarto doc using knitr
# Apply striped design to the table
knitr::kable(apply_functions)
```

## Parallel for loops

A normal for loop:

```{r}
#| label: for-loop-slow-sqrt
z <- list()
for (i in 1:10) {
  z[i] <- slow_sqrt(i)
}
```

. . .

Use `foreach` to write the same loop

```{r}
#| label: foreach-slow-sqrt
library(foreach)
z <- foreach(i = 1:10) %do%
  {
    slow_sqrt(i)
  }
```

## Parallel for loops

Use `doFuture` and `foreach` package to parallelize for loops

:::{.columns}

:::{.column width="50%"}

The **sequential** version

```{r}
#| label: foreach-slow-sqrt-sequential
library(foreach)

tic()
z <- foreach(i = 1:10) %do%
  {
    slow_sqrt(i)
  }
toc()
```

:::

:::{.column width="50%"}

The **parallel** version

:::{.fragment}

```{r}
#| label: foreach-slow-sqrt-parallel
library(doFuture)

tic()
z <- foreach(i = 1:10) %dofuture%
  {
    slow_sqrt(i)
  }
toc()
```

:::

:::

:::

## Future `purrr` functions

The [`furrr` package](https://furrr.futureverse.org/) offers parallel versions of [`purrr` functions](https://purrr.tidyverse.org/)

. . .

:::{.columns}

:::{.column width="50%"}

The **sequential** version

```{r}
#| label: purrr-slow-sqrt
library(purrr)

# the purrr version
tic()
z <- map(x, slow_sqrt)
toc()
```

:::

:::{.column width="50%"}

The **parallel** version

```{r}
#| label: furrr-slow-sqrt
library(furrr)

# the furrr version
tic()
z <- future_map(x, slow_sqrt)
toc()
```

:::

:::

## Close multisession

When you are done working in parallel, explicitly close your multisession:

```{r}
#| label: close-multisession
# close the multisession plan
plan(sequential)
```

## Replace slow code with C++

- Use the [`Rcpp` package](https://www.rcpp.org/) to re-write R functions in C++
 - `Rcpp` is also used internally by many R packages to make them faster
- Requirements: 
  - C++ compiler installed
  - Some knowledge of C++
  
- See [this book chapter](https://csgillespie.github.io/efficientR/performance.html#rcpp) and the [online documentation](https://www.rcpp.org/) for more info
 
## Rewrite a function in C++

**Example:** R function to calculate Fibonacci numbers

```{r}
#| label: fibonacci-r
# A function to calculate Fibonacci numbers
fibonacci_r <- function(n) {
  if (n < 2) {
    return(n)
  } else {
    return(fibonacci_r(n - 1) + fibonacci_r(n - 2))
  }
}
```

<br>

. . .

```{r}
#| label: fibonacci-r-30
# Calculate the 30th Fibonacci number
fibonacci_r(30)
```

## Rewrite a function in C++

Use `cppFunction` to rewrite the function in C++:

```{r}
#| label: fibonacci-cpp
library(Rcpp)

# Rewrite the fibonacci_r function in C++
fibonacci_cpp <- cppFunction(
  "int fibonacci_cpp(int n){
    if (n < 2){
      return(n);
    } else {
      return(fibonacci_cpp(n - 1) + fibonacci_cpp(n - 2));
    }
  }"
)
```

<br>

. . .

```{r}
#| label: fibonacci-cpp-30
# calculate the 30th Fibonacci number
fibonacci_cpp(30)
```

## Rewrite a function in C++

You can also source C++ functions from C++ scripts.

. . .

C++ script `fibonacci.cpp`:

```{cpp eval = FALSE}
#include "Rcpp.h"

// [[Rcpp::export]]
int fibonacci_cpp(const int x) {
   if (x < 2) return(x);
   return (fibonacci(x - 1)) + fibonacci(x - 2);
}
```

. . .

Then source the function in your R script using `sourceCpp`:

. . .

```{r eval=FALSE}
sourceCpp("fibonacci.cpp")

# Use the function in your R script like you are used to
fibonacci_cpp(30)
```


## How much faster is C++?

```{r}
#| label: benchmark-fibonacci
microbenchmark(
  r = fibonacci_r(30),
  rcpp = fibonacci_cpp(30),
  times = 10
)
```

# Summary

## Efficient R code and optimization

:::{.nonincremental}

- First: Can I run it somewhere else?
  - :wrench: Background job or cluster
- If not: Find bottlenecks in your code
  - :wrench: `profvis` package for profiling
  - :wrench: `microbenchmark` package for benchmarking
- Make the critical sections more efficient

:::

# Summary


![](img/pyramid_text.png){width=90%}


## Next lecture

#### Topic t.b.a.

<br>

:date: 17th July :clock4: 4-5 p.m. :round_pushpin: Webex

:bell: [Subscribe to the mailing list](https://lists.fu-berlin.de/listinfo/toolsAndTips)

:e-mail: For topic suggestions and/or feedback [send me an email](mailto:selina.baldauf@fu-berlin.de)

## Thank you for your attention :)
Questions?

# Appendix

## Cache function results

- Use the [`memoise` package](https://memoise.r-lib.org/)
- If functions are called many times with the same arguments
  - Avoids the recalculation
- Useful to e.g. improve the performance of a shiny app

## Cache function results

**Example**: Create a plot on a subset of the `iris` data set

```{r}
#| label: setup-memoise
# Example of using memoise to cache results
library(memoise)
library(ggplot2)

# Remove rows from plotting function
select_iris_species <- function(rows_to_remove) {
  iris_subset <- iris[-rows_to_remove, ]
  # Do a plot on the subset
  p <- ggplot(
    iris_subset,
    aes(x = Sepal.Length, y = Sepal.Width, color = Species)
  ) +
    geom_point()
}

# Version of the function with memoise
select_iris_species_mem <- memoise(select_iris_species)
```

## Cache function results

**Example**: Create a plot on a subset of the `iris` data set

```{r}
#| label: benchmark-iris-species
#| output-location: column
# Compare the two versions
result <- microbenchmark(
  no_cache = select_iris_species(10),
  cache = select_iris_species_mem(10)
)

autoplot(result)
```
